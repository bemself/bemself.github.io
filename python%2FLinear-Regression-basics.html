<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.1.22" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>python/Linear-Regression-basics: My Struggle — Life goes on...</title>
</head>
<body class="tc-body">

<section class="tc-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists " data-tags="" data-tiddler-title="python/Linear-Regression-basics"><div class="tc-tiddler-title"><div class="tc-titlebar"><span class="tc-tiddler-controls"><span class=" tc-reveal"><button aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span></span><span><span class="tc-tiddler-title-icon" style="fill:;"></span><h2 class="tc-title">python/Linear-Regression-basics</h2></span></div><div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div></div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal"><div class="tc-subtitle"><a class="tc-tiddlylink tc-tiddlylink-missing" href=".html"></a>26th July 2020</div></div><div class=" tc-reveal">
<div class="tc-tags-wrapper"></div>
</div>

<div class="tc-tiddler-body tc-reveal"><hr><p>title: Python 线性回归（Linear Regression) 基本理解<br>date: 2020-01-08<br>edit: 2020-01-08<br>layout: post<br>status: Completed<br>categories:</p><ul><li><p>Python<br>tags:</p></li><li><p>Python<br>description:  大概回顾了下线性回归是什么，做什么，怎么做~</p></li></ul><hr><h1>背景</h1><p>学习 <a href="https://realpython.com/linear-regression-in-python/" target="_blank">Linear Regression in Python – Real Python</a>，对线性回归理论上的理解做个回顾，文章是前天读完，今天凭着记忆和理解写一遍，再回温更正。</p><h1>线性回归(Linear Regression)</h1><p>刚好今天听大妈讲机器学习，各种复杂高大上的算法，其背后都是在求”拟合“。</p><p>线性回归估计是最简单的拟合了。也是基础中的基础。</p><p>依然是从字面上先来试着拆解和组合：</p><p>首先，<strong>Regression</strong> 回归，指的是研究变量之间的关系，这个由来在<a href="https://bemself.github.io/python/Python-Linear-Regression-Concept.html" target="_blank">Python 线性回归（Linear Regression) - 到底什么是 regression？</a>一文中讲多了，这里不多重复。</p><p>然后，<strong>linear</strong> 线性，很直观：直线。</p><p>二者连在一起，便是：变量之间呈直线关系。</p><p><strong>那具体是哪些变量之间？</strong></p><p>因变量 y 和 自变量 (x1...xr) 之间。</p><p><code>𝑦 = 𝛽₀ + 𝛽₁𝑥₁ + ⋯ + 𝛽ᵣ𝑥ᵣ + 𝜀</code></p><p>当只有一个 x1 的时候，就是最简单的线性回归 <code>𝑦 = 𝛽₀ + 𝛽₁𝑥₁</code>。</p><p><strong>具体怎么理解这个公式呢？</strong></p><p>举个简化的例子：员工的工资 y 与 学历 x 的关系。</p><blockquote><p>假设学历越高，工资也越高，二者是某种程度上的线性关系，</p></blockquote><p>那在<strong>理论上</strong>会存在这么一个公式 <code>y = 𝛽₀ + 𝛽₁𝑥</code>，其中，x1...xn, y1...yn：</p><ul><li><p>x 和 y 的数据很容易拿到（当然合法渠道了，假设你是 hr 总监）</p></li><li><p>hr 总监想做的是，根据这组 (x y)数据，找出 𝛽₀ 和 𝛽₁ 的值，二者称为<strong>回归系数</strong></p></li><li><p>这样，下一次招聘的时候，根据应聘者的学历，可以先估一个工资了。</p></li></ul><p>这个过程便是：数据 -&gt; 建立模型 f(x) -&gt; 预测</p><p>只是，理论和实际总是有差别的，就像 1/3 ~= 0.3333333333333...</p><p>所以，<strong>实际拟合</strong>到的模型可能是这样的： <code>f(x) = 𝑏₀ + 𝑏₁𝑥</code></p><p>𝛽₀ 和 𝛽₁ 分别与 𝑏₀ 和 𝑏₁ 有多接近？</p><p>当然是拟合出来的越接近越好；<br><img src="https://files.realpython.com/media/fig-lin-reg.a506035b654a.png"></p><p><strong>如何知道有多接近？</strong></p><p>简单，</p><ul><li><p>将 x1...xn 代入到拟合后的模型中 f(x),</p></li><li><p>求得新的 new_y1...new_yn</p></li><li><p>再跟原 y1...yn 比较，比如 <code>new_y1 - y1</code> （称为残差）</p><ul><li><p>这里要用到最小二乘法（method of ordinary least squares）</p></li><li><p>因为残差可能是负的，</p></li><li><p>所以用残差平方和</p></li></ul></li></ul><p><strong>回归要解决的问题就是：</strong>以最简单的线性回归为例：</p><ul><li><p>找到最佳的 𝑏₀ 和 𝑏₁， 使模型 <code>f(x) = 𝑏₀ + 𝑏₁𝑥</code> 最接近理论上的线性模型 <code>y = 𝛽₀ + 𝛽₁𝑥</code></p></li><li><p>然后，用这个拟合好的模型 <code>f(x) = 𝑏₀ + 𝑏₁𝑥</code> 来预测新的数据</p></li></ul><h1>线性回归好多种</h1><p>除了上面例子中的最简单的线性回归，还有：</p><ul><li><p>多元线性回归：Multiple linear Regression</p><ul><li><p><code>𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂</code></p></li></ul></li><li><p>多项式回归：Polynomial Regression</p><ul><li><p><code>𝑓(𝑥) = 𝑏₀ + 𝑏₁𝑥 + 𝑏₂𝑥²</code>....</p></li></ul></li></ul><p>即从二维转为三维、多维空间拟合了。这个有点复杂了，不过原理和前面是相通的。</p><h1>拟合的程度</h1><p>过犹不及用在这里也适合，过度拟合也很脆弱的，因为可能新增加一个或几个数据就破坏了之前的完美，就好像专门为你定制的帽子戴在别人头上就没那么合适和美了。</p><p><img src="https://files.realpython.com/media/poly-reg.5790f47603d8.png" title="overfitting">](https://files.realpython.com/media/poly-reg.5790f47603d8.png)</p><p>当然，拟合的不及也不好，这时候可能就要换模型或者调参了吧</p><p><img src="https://files.realpython.com/media/poly-reg.5790f47603d8.png" title="underfitting"></p><h1>Reference</h1><ul><li><p><a href="https://realpython.com/linear-regression-in-python/" target="_blank">Linear Regression in Python – Real Python</a></p></li></ul><h1>Changelog</h1><ul><li><p>2020-01-08 init</p></li></ul></div>



</div>

</p>
</section>
</body>
</html>
